{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos nustros datos de un pdf local\n",
    "loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "\n",
    "#Cargamos nuestros datos de un pdf en la nueve\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 201014 characters in your document\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de documentos (pdf's)\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "\n",
    "# Caracteres en el documento\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos la division de nuestros datos\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# Dividimos nuestros datos\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 240 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Cree incrustaciones de sus documentos para prepararse para la búsqueda semántica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# pinecone es una base de datos en la nueve que nos permitira guardar nuestros \"Embeddings\"\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "PINECONE_API_KEY = \"\" \n",
    "PINECONE_API_ENV = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos nuestros \"Embeddings\"\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializar pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subimos nuestros fracmentos del decumento con sus \"Embeddings\" en la base de datos pinecone\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una pregunta\n",
    "query = \"What are examples of good data science teams?\"\n",
    "\n",
    "# Busca los documentos con mayor similitud de significado semantico (usando los \"Embeddings\") con la pregunta\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos nuestro LLM\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\"\"\"Inicimaos una cadena con nuestro LLM tipo \"stuff\" que significa que \n",
    "tomara los dumentos vistos anterior mente y los pendra en el promt para hacer la pregunta\n",
    "\"\"\"\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta\n",
    "query = \"What is the collect stage of data maturity?\"\n",
    "# Documentos mas similares a la pregunta\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The collect stage of data maturity is the first stage of data science maturity. It focuses on collecting internal or external datasets. An example of this stage is gathering sales records and corresponding weather data.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respuesta por parte de nuestro LLM\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79e198fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta\n",
    "query =  \"what are the steps in cleaning the data?\" \n",
    "# Documentos mas similares a la pregunta\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a064bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The steps in cleaning the data include outlier removal, Gaussian filter, exponential smoothing, median filter, distribution fitting, feature hashing, wrapper methods, sensitivity analysis, self organizing maps, deduplication, normalization, format conversion, fast Fourier transform (FFT), discrete wavelet transform, coordinate transform.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respuesta por parte de nuestro LLM\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c80ed8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Tokenization POS staging is a part-of-speech tagging process that eliminates words other than nouns and verbs and uses raw term counts instead of TF/IDF weighted terms.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pregunta\n",
    "query =  \"what is tokenization POS staging?\"\n",
    "\n",
    "# Documentos mas similares a la pregunta\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)\n",
    "\n",
    "# respuesta por parte de nuestro LLM\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
